{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/thinhlv/data/anaconda/envs/khanhlinh/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/data/thinhlv/data/anaconda/envs/khanhlinh/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:25: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import torch\n",
    "import pytorchvideo\n",
    "from pytorchvideo.data import LabeledVideoDataset,Kinetics, make_clip_sampler,labeled_video_dataset\n",
    "\n",
    "from pytorchvideo.transforms import(\n",
    "    ApplyTransformToKey,Normalize,RandomShortSideScale,Permute,UniformTemporalSubsample,  ShortSideScale\n",
    ")\n",
    "\n",
    "from torchvision.transforms import(\n",
    "    Compose,Lambda,RandomCrop,RandomHorizontalFlip,Resize,\n",
    ")\n",
    "from torchvision.transforms._transforms_video import(\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo\n",
    ")\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule,seed_everything,Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint,LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR,ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report\n",
    "import torchmetrics\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import numpy as np\n",
    "import pytorchvideo\n",
    "import pytorch_lightning as pl\n",
    "import pytorchvideo.models.hub.slowfast as slowfast\n",
    "from lion_pytorch import Lion\n",
    "import pytorchvideo.models.hub.x3d as x3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define the transform video data\n",
    "side_size = 300\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "crop_size = 256\n",
    "num_frames = 32\n",
    "sampling_rate = 2\n",
    "frames_per_second = 30\n",
    "slowfast_alpha = 4\n",
    "num_clips = 10\n",
    "num_crops = 3\n",
    "\n",
    "class PackPathway(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Transform for converting video frames as a list of tensors. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, frames: torch.Tensor):\n",
    "        fast_pathway = frames\n",
    "        # Perform temporal sampling from the fast pathway.\n",
    "        slow_pathway = torch.index_select(\n",
    "            frames,\n",
    "            1,\n",
    "            torch.linspace(\n",
    "                0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha\n",
    "            ).long(),\n",
    "        )\n",
    "        frame_list = [slow_pathway, fast_pathway]\n",
    "        return frame_list\n",
    "\n",
    "transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "            NormalizeVideo(mean, std),\n",
    "            ShortSideScale(\n",
    "                size=side_size\n",
    "            ),\n",
    "            CenterCropVideo(crop_size),\n",
    "            PackPathway()\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "train_transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "            NormalizeVideo(mean, std),\n",
    "            RandomShortSideScale(min_size=256, max_size=320),\n",
    "            RandomCrop(256),\n",
    "            RandomHorizontalFlip(p=0.5),\n",
    "            ShortSideScale(\n",
    "                size=side_size\n",
    "            ),\n",
    "            CenterCropVideo(crop_size),\n",
    "            PackPathway()\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The duration of the input clip is also specific to the model.\n",
    "clip_duration = (num_frames * sampling_rate)/frames_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model using slowfast_r50 is backbone model and backend is pytorch lightning\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "NUM_WORKERS =  os.cpu_count() or 0\n",
    "from torchmetrics.classification import BinaryAccuracy,BinaryF1Score\n",
    "class videoClassifer(LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.prepresentation=slowfast.slowfast_r50(pretrained=True) # slowfast_r50 is pretrained model\n",
    "        self.prepresentation.blocks[6].proj=nn.Linear(in_features=2304, out_features=1000, bias=True) # modify project layer to vector prepresentation \n",
    "        \n",
    "        self.fc=nn.Sequential( # Define fully connected\n",
    "            nn.Linear(in_features=1000, out_features=500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=500,out_features=400),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(in_features=400,out_features=1)\n",
    "        )\n",
    "        for param in self.prepresentation .blocks[:] .parameters(): # Freeze parameters of pretrained model\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "            \n",
    "        self.lr=1e-2 # learning rate\n",
    "       \n",
    "        self.batch_size=16 \n",
    "\n",
    "        self.numworker=NUM_WORKERS \n",
    "        # evalation\n",
    "        self.metrics=BinaryAccuracy().to(self.device)  # Define Accuracy metris\n",
    "        self.F1_score=BinaryF1Score().to(self.device) # Define F1 Score \n",
    "        \n",
    "      \n",
    "\n",
    "        self.criterion=nn.BCEWithLogitsLoss() # Loss function\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.prepresentation(x)\n",
    "        x=self.fc(x)\n",
    "\n",
    "        return x\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        \n",
    "        opt = Lion(params=self.parameters(),lr=self.lr, weight_decay=1e-2)  # Optimizer\n",
    "        scheduler=CosineAnnealingLR(optimizer=opt,T_max=10,eta_min=1e-5,last_epoch=-1) # scheduler purpose control \n",
    "        return {\"optimizer\":opt,\"lr_scheduler\":scheduler}\n",
    "    # define train dataloader to load dataset from folder \n",
    "    def train_dataloader(self):\n",
    "        dataset=labeled_video_dataset(\"data/train\",clip_sampler=make_clip_sampler(\"random\",2),transform=transform ,decode_audio=False)\n",
    "        loader=DataLoader(dataset,batch_size=self.batch_size,num_workers=self.numworker,pin_memory=True)\n",
    "        return loader\n",
    "    # Define training step through training model \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        video,label=batch[\"video\"],batch[\"label\"].to(torch.float32).detach()  # \n",
    "        out=self(video).squeeze(1) \n",
    "        loss=self.criterion(out,label) # loss function  \n",
    "        return {\"loss\":loss,'preds': out.detach(), 'target': label}\n",
    "    \n",
    "    # define validation dataloader to load dataset from folder \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        dataset=labeled_video_dataset(\"data/val\",clip_sampler=make_clip_sampler(\"random\",2),transform=transform,decode_audio=False)\n",
    "        loader=DataLoader(dataset,batch_size=self.batch_size,num_workers=self.numworker,pin_memory=True)\n",
    "        return loader\n",
    "    # Define validation step through training model \n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        video,label=batch[\"video\"],batch[\"label\"].to(torch.float32).detach()\n",
    "        out=self(video).squeeze(1) \n",
    "        loss=self.criterion(out,label)\n",
    "        return {\"loss\":loss,'preds': out.detach(), 'target': label}\n",
    "        \n",
    "    # Define testing dataloader\n",
    "    def test_dataloader(self):\n",
    "        dataset=labeled_video_dataset(\"data/test\",clip_sampler=make_clip_sampler(\"random\",2),transform=transform,decode_audio=False)\n",
    "        loader=DataLoader(dataset,batch_size=self.batch_size,num_workers=self.numworker,pin_memory=True)\n",
    "        return loader\n",
    "    \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        video,label=batch[\"video\"],batch[\"label\"]\n",
    "        out=self(video).squeeze(1) \n",
    "        return {\"label\":label.detach(),\"pred\":out.detach()}\n",
    "    def test_epochs_end(self, outputs):\n",
    "        label=torch.cat([x[\"label\"] for x in outputs]).cpu().numpy()\n",
    "        pred=torch.cat([x[\"pred\"] for x in outputs]).cpu().numpy()\n",
    "        pred=np.where(pred>0.5,1,0)\n",
    "        print(classification_report(label,pred))\n",
    "    # When end epoch training logging some metrics and loss function\n",
    "    def training_epoch_end(self, outputs):\n",
    "       \n",
    "        avg_loss = torch.cat([x['loss'].reshape(-1,1) for x in outputs],0).mean()\n",
    "        preds = torch.cat([x['preds'] for x in outputs], dim=0)\n",
    "        target = torch.cat([x['target'] for x in outputs], dim=0)\n",
    "    \n",
    "        \n",
    "        self.F1_score.update(preds, target)\n",
    "        self.metrics.update(preds, target)\n",
    "        \n",
    "        metric_value = self.metrics.compute()\n",
    "        F1_score=self.F1_score.compute()\n",
    "       \n",
    "        self.log('train_loss', avg_loss, on_epoch=True)\n",
    "        self.log('train_metric', metric_value, on_epoch=True)\n",
    "        self.log(\"train_f1_score\",F1_score,on_epoch=True)\n",
    "\n",
    "    # When end epoch testing logging some metrics and loss function\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.cat([x['loss'].reshape(-1,1) for x in outputs],0).mean()\n",
    "        preds = torch.cat([x['preds'] for x in outputs], dim=0)\n",
    "        target = torch.cat([x['target'] for x in outputs], dim=0)\n",
    "    \n",
    "        self.F1_score.update(preds, target)\n",
    "        self.metrics.update(preds, target)\n",
    "        metric_value = self.metrics.compute()\n",
    "        F1_score=self.F1_score.compute()\n",
    "        self.F1_score.update(preds, target)\n",
    "        self.log('val_loss', avg_loss, on_epoch=True)\n",
    "        self.log('val_metric', metric_value, on_epoch=True)\n",
    "        self.log(\"val_f1_score\",F1_score,on_epoch=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=videoClassifer() # initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Initialize the logger'''\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "wandb_logger = WandbLogger(project=\"Video_classify\",job_type='train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback=ModelCheckpoint(monitor=\"val_loss\",dirpath=r\"/checkpoint\",filename=\"VideoClassifierSlowFast_r50_300\",save_last=True) #  Checkpoint callback to save checkpoint model\n",
    "lr_monitor=LearningRateMonitor(logging_interval=\"epoch\") # Monitor learning rate\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.00, patience=3, verbose=False, mode=\"max\") # Early stopping callback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(accelerator=\"gpu\", devices=[0,1,2,3], # trainer device \n",
    "                  callbacks=[lr_monitor,checkpoint_callback], \n",
    "                  enable_progress_bar=True,logger=wandb_logger,strategy='dp'\n",
    "                  ,max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model) # fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from checkpoint file\n",
    "model_classifier=videoClassifer.load_from_checkpoint(r\"checkpoint/VideoClassifierSlowFast_50_size_300.ckpt\") # load the model from checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader=model_classifier.test_dataloader() # load test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total prediction time: 36.28 seconds\n",
      "Average prediction time per sample: 0.5669 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "predicts = []\n",
    "labels = []\n",
    "start_time = time.time()\n",
    "# num_samples = len(test_loader)\n",
    "model_classifier.eval()\n",
    "for batch in test_loader:\n",
    "    video = batch[\"video\"]\n",
    "    label = batch[\"label\"]\n",
    "    \n",
    "    preds = model_classifier(video)\n",
    "    post_act = torch.nn.Sigmoid()\n",
    "\n",
    "    preds = post_act(preds)\n",
    "    preds = preds > 0.5\n",
    "    predicts.append(preds[0].numpy())\n",
    "    labels.append(label[0].numpy())\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_sample = total_time / 64\n",
    "print(f\"Total prediction time: {total_time:.2f} seconds\")\n",
    "print(f\"Average prediction time per sample: {avg_time_per_sample:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77        24\n",
      "           1       0.85      0.88      0.86        40\n",
      "\n",
      "    accuracy                           0.83        64\n",
      "   macro avg       0.82      0.81      0.82        64\n",
      "weighted avg       0.83      0.83      0.83        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=predicts,y_true=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f0eb25846a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "mt=confusion_matrix(y_pred=predicts,y_true=labels)\n",
    "disp=ConfusionMatrixDisplay(mt,display_labels=[\"Fight\",\"Normal\"])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0097]], grad_fn=<SigmoidBackward0>)\n",
      "Fight\n"
     ]
    }
   ],
   "source": [
    "video_path=r\"/data/test/Fight/_q5Nwh4Z6ao_6.avi\"\n",
    "# Load video data\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "start_sec = 0\n",
    "end_sec = start_sec + clip_duration\n",
    "\n",
    "# Initialize an EncodedVideo helper class and load the video\n",
    "video = EncodedVideo.from_path(video_path)\n",
    "\n",
    "# Load the desired clip\n",
    "video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
    "video_data = transform(video_data)\n",
    "inputs = video_data[\"video\"]\n",
    "inputs = [i[None, ...] for i in inputs]\n",
    "\n",
    "preds = model_classifier(inputs)\n",
    "\n",
    "# Get the predicted classes\n",
    "post_act = torch.nn.Sigmoid()\n",
    "preds = post_act(preds)\n",
    "labels_names=[\"Fight\",\"Normal\"]\n",
    "print(preds)\n",
    "print(labels_names[preds[0]>0.5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
